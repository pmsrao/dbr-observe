{
  "workflows": {
    "daily_observability_pipeline": {
      "name": "Daily Observability Pipeline",
      "description": "Daily processing of observability data from bronze to gold layers",
      "schedule": {
        "quartz_cron_expression": "0 0 2 * * ?",
        "timezone_id": "UTC",
        "pause_status": "UNPAUSED"
      },
      "tasks": [
        {
          "task_key": "daily_observability_pipeline",
          "description": "Main daily observability pipeline",
          "python_wheel_task": {
            "package_name": "observability_pipeline",
            "entry_point": "main",
            "parameters": []
          },
          "libraries": [
            {
              "pypi": {
                "package": "pyspark==3.4.0"
              }
            }
          ],
          "new_cluster": {
            "spark_version": "13.3.x-scala2.12",
            "node_type_id": "i3.xlarge",
            "num_workers": 2,
            "spark_conf": {
              "spark.sql.adaptive.enabled": "true",
              "spark.sql.adaptive.coalescePartitions.enabled": "true",
              "spark.sql.adaptive.skewJoin.enabled": "true"
            },
            "autoscale": {
              "min_workers": 1,
              "max_workers": 4
            },
            "aws_attributes": {
              "availability": "ON_DEMAND",
              "zone_id": "us-west-2a"
            }
          },
          "timeout_seconds": 3600,
          "retry_on_timeout": true,
          "max_retries": 2,
          "retry_on_timeout": true
        }
      ],
      "email_notifications": {
        "on_start": ["data-platform-team@company.com"],
        "on_success": ["data-platform-team@company.com"],
        "on_failure": ["data-platform-team@company.com", "oncall@company.com"]
      },
      "webhook_notifications": {
        "on_start": [
          {
            "id": "slack_start",
            "url": "https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK"
          }
        ],
        "on_success": [
          {
            "id": "slack_success",
            "url": "https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK"
          }
        ],
        "on_failure": [
          {
            "id": "slack_failure",
            "url": "https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK"
          }
        ]
      },
      "max_concurrent_runs": 1,
      "tags": {
        "environment": "prod",
        "team": "data-platform",
        "cost_center": "engineering",
        "data_product": "observability"
      }
    },
    "watermark_management": {
      "name": "Watermark Management",
      "description": "Daily watermark cleanup and validation",
      "schedule": {
        "quartz_cron_expression": "0 30 1 * * ?",
        "timezone_id": "UTC",
        "pause_status": "UNPAUSED"
      },
      "tasks": [
        {
          "task_key": "watermark_management",
          "description": "Watermark cleanup and validation",
          "python_wheel_task": {
            "package_name": "watermark_management",
            "entry_point": "main",
            "parameters": []
          },
          "libraries": [
            {
              "pypi": {
                "package": "pyspark==3.4.0"
              }
            }
          ],
          "new_cluster": {
            "spark_version": "13.3.x-scala2.12",
            "node_type_id": "i3.large",
            "num_workers": 1,
            "spark_conf": {
              "spark.sql.adaptive.enabled": "true"
            }
          },
          "timeout_seconds": 1800,
          "retry_on_timeout": true,
          "max_retries": 2
        }
      ],
      "email_notifications": {
        "on_failure": ["data-platform-team@company.com"]
      },
      "max_concurrent_runs": 1,
      "tags": {
        "environment": "prod",
        "team": "data-platform",
        "cost_center": "engineering",
        "data_product": "observability"
      }
    }
  }
}
